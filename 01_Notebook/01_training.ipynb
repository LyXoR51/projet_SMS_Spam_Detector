{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89e09487",
   "metadata": {},
   "source": [
    "# 1. Libraries\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7aec5f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchinfo import summary\n",
    "import torch.optim as optim\n",
    "from torchmetrics import Accuracy\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import mlflow\n",
    "import os\n",
    "from torchmetrics.classification import BinaryAccuracy\n",
    "\n",
    "\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2302bcd7",
   "metadata": {},
   "source": [
    "# 2. Data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df44565b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#start engine\n",
    "postgres_database = os.environ[\"POSTGRES_DATABASE\"]\n",
    "engine = create_engine(postgres_database, echo=True)\n",
    "table_name = 'messages_spam_detector'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55878374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-27 00:32:06,839 INFO sqlalchemy.engine.Engine select pg_catalog.version()\n",
      "2025-10-27 00:32:06,841 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-10-27 00:32:06,885 INFO sqlalchemy.engine.Engine select current_schema()\n",
      "2025-10-27 00:32:06,885 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-10-27 00:32:06,926 INFO sqlalchemy.engine.Engine show standard_conforming_strings\n",
      "2025-10-27 00:32:06,927 INFO sqlalchemy.engine.Engine [raw sql] {}\n"
     ]
    }
   ],
   "source": [
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0532d000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-27 00:32:18,547 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-10-27 00:32:18,547 INFO sqlalchemy.engine.Engine \n",
      "    SELECT *\n",
      "    FROM messages_spam_detector\n",
      "    WHERE label IS NOT NULL\n",
      "    ORDER BY id ASC\n",
      "\n",
      "2025-10-27 00:32:18,548 INFO sqlalchemy.engine.Engine [generated in 0.00142s] {}\n"
     ]
    }
   ],
   "source": [
    "stmt = text(f\"\"\"\n",
    "    SELECT *\n",
    "    FROM {table_name}\n",
    "    WHERE label IS NOT NULL\n",
    "    ORDER BY id ASC\n",
    "\"\"\")\n",
    "\n",
    "result = conn.execute(stmt)\n",
    "data = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3e58e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "      <th>label_predict</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>ham</td>\n",
       "      <td>None</td>\n",
       "      <td>1761506577863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ham</td>\n",
       "      <td>None</td>\n",
       "      <td>1761506577863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>spam</td>\n",
       "      <td>None</td>\n",
       "      <td>1761506577863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>ham</td>\n",
       "      <td>None</td>\n",
       "      <td>1761506577863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>ham</td>\n",
       "      <td>None</td>\n",
       "      <td>1761506577863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            content label label_predict  \\\n",
       "0   0  Go until jurong point, crazy.. Available only ...   ham          None   \n",
       "1   1                   Ok lar... Joking wif u oni...      ham          None   \n",
       "2   2  Free entry in 2 a wkly comp to win FA Cup fina...  spam          None   \n",
       "3   3  U dun say so early hor... U c already then say...   ham          None   \n",
       "4   4  Nah I don't think he goes to usf, he lives aro...   ham          None   \n",
       "\n",
       "      created_at  \n",
       "0  1761506577863  \n",
       "1  1761506577863  \n",
       "2  1761506577863  \n",
       "3  1761506577863  \n",
       "4  1761506577863  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4f96ba",
   "metadata": {},
   "source": [
    "# 3. Preprocess\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648d4c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg seq len 23.238924356742118\n",
      "max seq len 260\n"
     ]
    }
   ],
   "source": [
    "# RUsing 1 and 0 for binary classification\n",
    "data['label_bin'] = data['label'].apply(lambda x: 1  if x =='Spam' else 0)\n",
    "\n",
    "#tokenization\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "def encode_texts(texts):\n",
    "    return [tokenizer.encode(text) for text in texts]\n",
    "\n",
    "data['content_tokenised'] = encode_texts(data['content'])\n",
    "\n",
    "#sequence length distribution\n",
    "seq_lens = [len(seq) for seq in data['content_tokenised']]\n",
    "print(f\"avg seq len {np.mean(seq_lens)}\")\n",
    "print(f\"max seq len {np.max(seq_lens)}\")\n",
    "#standardise length distribution\n",
    "\n",
    "def pad_sequences(sequences, max_length=25):\n",
    "    return [seq[:max_length] + [0] * (max_length - len(seq)) for seq in sequences]\n",
    "\n",
    "data['content_tokenised'] = pad_sequences(data['content_tokenised'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7edae4a",
   "metadata": {},
   "source": [
    "# 4. Training\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cb8718",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = torch.tensor(texts, dtype=torch.long)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx], self.labels[idx]\n",
    "\n",
    "#Creating a dataset instance\n",
    "df_dataset = SpamDataset(data['content_tokenised'], data['label_bin'])\n",
    "\n",
    "# Split dataset into training (80%) and validation (20%)\n",
    "train_size = int(0.8 * len(df_dataset))\n",
    "val_size = len(df_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(df_dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "text, label = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2ca050c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextClassifier(\n",
      "  (embedding): Embedding(100277, 32, padding_idx=0)\n",
      "  (pooling): AdaptiveAvgPool1d(output_size=1)\n",
      "  (fc): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "TextClassifier                           [32, 1]                   --\n",
       "â”œâ”€Embedding: 1-1                         [32, 25, 32]              3,208,864\n",
       "â”œâ”€AdaptiveAvgPool1d: 1-2                 [32, 32, 1]               --\n",
       "â”œâ”€Linear: 1-3                            [32, 1]                   33\n",
       "==========================================================================================\n",
       "Total params: 3,208,897\n",
       "Trainable params: 3,208,897\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 102.68\n",
       "==========================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 0.21\n",
       "Params size (MB): 12.84\n",
       "Estimated Total Size (MB): 13.05\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = tokenizer.n_vocab\n",
    "\n",
    "#model defition\n",
    "class TextClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super(TextClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.pooling = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        pooled = self.pooling(embedded.permute(0, 2, 1)).squeeze(2)\n",
    "        return torch.sigmoid(self.fc(pooled))\n",
    "\n",
    "model = TextClassifier(vocab_size=vocab_size,\n",
    "                      embed_dim=32, \n",
    "                      num_class=1)\n",
    "\n",
    "\n",
    "#describe model\n",
    "print(model)\n",
    "summary(model, input_data=text)  # (batch_size, input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "53afa1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/26 15:52:46 INFO mlflow.tracking.fluent: Experiment with name 'SMS_Spam_Detector' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='s3://fp-private-bucket/mlflow/9', creation_time=1761490366984, experiment_id='9', last_update_time=1761490366984, lifecycle_stage='active', name='SMS_Spam_Detector', tags={}>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(os.environ[\"MLFLOW_TRACKING_URI\"])\n",
    "experiment_name = 'SMS_Spam_Detector'\n",
    "\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fe0322d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get cpu or gpu for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "673f2e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, metrics_fn, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        pred = model(X).squeeze(1)\n",
    "        loss = loss_fn(pred, y)  # y float\n",
    "        accuracy = metrics_fn(pred, y.int())  # y int pour metric\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            step = batch + epoch * len(dataloader)\n",
    "            mlflow.log_metric(\"loss\", loss.item(), step=step)\n",
    "            mlflow.log_metric(\"accuracy\", accuracy.item(), step=step)\n",
    "            print(f\"Epoch {epoch+1}, batch {batch}, loss={loss.item():.4f}, acc={accuracy.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5ddce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader, model, loss_fn, metrics_fn, epoch):\n",
    "    model.eval()\n",
    "    eval_loss, eval_accuracy = 0.0, 0.0\n",
    "    num_batches = len(dataloader)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X).squeeze(1)  \n",
    "            eval_loss += loss_fn(pred, y).item()\n",
    "            eval_accuracy += metrics_fn(pred, y).item()\n",
    "\n",
    "    eval_loss /= num_batches\n",
    "    eval_accuracy /= num_batches\n",
    "    mlflow.log_metric(\"eval_loss\", eval_loss, step=epoch)\n",
    "    mlflow.log_metric(\"eval_accuracy\", eval_accuracy, step=epoch)\n",
    "\n",
    "    print(f\"Eval: loss={eval_loss:.4f}, acc={eval_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c6c1bdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "loss_fn = nn.BCELoss()\n",
    "metric_fn = BinaryAccuracy().to(device)\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fbf13cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception during reset or similar\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lyxor/miniconda3/envs/DP/lib/python3.10/site-packages/sqlalchemy/pool/base.py\", line 985, in _finalize_fairy\n",
      "    fairy._reset(\n",
      "  File \"/home/lyxor/miniconda3/envs/DP/lib/python3.10/site-packages/sqlalchemy/pool/base.py\", line 1433, in _reset\n",
      "    pool._dialect.do_rollback(self)\n",
      "  File \"/home/lyxor/miniconda3/envs/DP/lib/python3.10/site-packages/sqlalchemy/engine/default.py\", line 711, in do_rollback\n",
      "    dbapi_connection.rollback()\n",
      "psycopg2.OperationalError: SSL connection has been closed unexpectedly\n",
      "\n",
      "Exception during reset or similar\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lyxor/miniconda3/envs/DP/lib/python3.10/site-packages/sqlalchemy/pool/base.py\", line 985, in _finalize_fairy\n",
      "    fairy._reset(\n",
      "  File \"/home/lyxor/miniconda3/envs/DP/lib/python3.10/site-packages/sqlalchemy/pool/base.py\", line 1433, in _reset\n",
      "    pool._dialect.do_rollback(self)\n",
      "  File \"/home/lyxor/miniconda3/envs/DP/lib/python3.10/site-packages/sqlalchemy/engine/default.py\", line 711, in do_rollback\n",
      "    dbapi_connection.rollback()\n",
      "psycopg2.OperationalError: SSL connection has been closed unexpectedly\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 -------------------------------\n",
      "Epoch 1, batch 0, loss=0.7023, acc=0.4062\n",
      "Epoch 1, batch 100, loss=0.6496, acc=0.8438\n",
      "Eval: loss=0.6313, acc=0.8491\n",
      "Epoch 2 -------------------------------\n",
      "Epoch 2, batch 0, loss=0.6270, acc=0.8438\n",
      "Epoch 2, batch 100, loss=0.6030, acc=0.8438\n",
      "Eval: loss=0.5450, acc=0.8843\n",
      "Epoch 3 -------------------------------\n",
      "Epoch 3, batch 0, loss=0.5590, acc=0.8438\n",
      "Epoch 3, batch 100, loss=0.5363, acc=0.8125\n",
      "Eval: loss=0.4624, acc=0.8890\n",
      "Epoch 4 -------------------------------\n",
      "Epoch 4, batch 0, loss=0.4291, acc=0.8750\n",
      "Epoch 4, batch 100, loss=0.3901, acc=0.9375\n",
      "Eval: loss=0.3913, acc=0.8900\n",
      "Epoch 5 -------------------------------\n",
      "Epoch 5, batch 0, loss=0.3462, acc=0.9062\n",
      "Epoch 5, batch 100, loss=0.3156, acc=0.9375\n",
      "Eval: loss=0.3353, acc=0.9013\n",
      "Epoch 6 -------------------------------\n",
      "Epoch 6, batch 0, loss=0.3977, acc=0.8438\n",
      "Epoch 6, batch 100, loss=0.3030, acc=0.9062\n",
      "Eval: loss=0.2912, acc=0.9061\n",
      "Epoch 7 -------------------------------\n",
      "Epoch 7, batch 0, loss=0.3373, acc=0.9062\n",
      "Epoch 7, batch 100, loss=0.2429, acc=0.9375\n",
      "Eval: loss=0.2559, acc=0.9193\n",
      "Epoch 8 -------------------------------\n",
      "Epoch 8, batch 0, loss=0.2250, acc=0.9375\n",
      "Epoch 8, batch 100, loss=0.3740, acc=0.8750\n",
      "Eval: loss=0.2275, acc=0.9297\n",
      "Epoch 9 -------------------------------\n",
      "Epoch 9, batch 0, loss=0.1823, acc=0.9688\n",
      "Epoch 9, batch 100, loss=0.2005, acc=0.9375\n",
      "Eval: loss=0.2036, acc=0.9402\n",
      "Epoch 10 -------------------------------\n",
      "Epoch 10, batch 0, loss=0.0831, acc=1.0000\n",
      "Epoch 10, batch 100, loss=0.2434, acc=0.9062\n",
      "Eval: loss=0.1837, acc=0.9487\n",
      "Epoch 11 -------------------------------\n",
      "Epoch 11, batch 0, loss=0.1072, acc=1.0000\n",
      "Epoch 11, batch 100, loss=0.1249, acc=1.0000\n",
      "Eval: loss=0.1673, acc=0.9553\n",
      "Epoch 12 -------------------------------\n",
      "Epoch 12, batch 0, loss=0.2312, acc=0.9062\n",
      "Epoch 12, batch 100, loss=0.0939, acc=1.0000\n",
      "Eval: loss=0.1539, acc=0.9581\n",
      "Epoch 13 -------------------------------\n",
      "Epoch 13, batch 0, loss=0.1128, acc=0.9688\n",
      "Epoch 13, batch 100, loss=0.1175, acc=0.9688\n",
      "Eval: loss=0.1426, acc=0.9591\n",
      "Epoch 14 -------------------------------\n",
      "Epoch 14, batch 0, loss=0.2510, acc=0.9062\n",
      "Epoch 14, batch 100, loss=0.1905, acc=0.9375\n",
      "Eval: loss=0.1330, acc=0.9638\n",
      "Epoch 15 -------------------------------\n",
      "Epoch 15, batch 0, loss=0.0562, acc=0.9688\n",
      "Epoch 15, batch 100, loss=0.0698, acc=0.9688\n",
      "Eval: loss=0.1252, acc=0.9667\n",
      "Epoch 16 -------------------------------\n",
      "Epoch 16, batch 0, loss=0.0785, acc=1.0000\n",
      "Epoch 16, batch 100, loss=0.0556, acc=1.0000\n",
      "Eval: loss=0.1183, acc=0.9705\n",
      "Epoch 17 -------------------------------\n",
      "Epoch 17, batch 0, loss=0.0579, acc=1.0000\n",
      "Epoch 17, batch 100, loss=0.1025, acc=0.9688\n",
      "Eval: loss=0.1125, acc=0.9714\n",
      "Epoch 18 -------------------------------\n",
      "Epoch 18, batch 0, loss=0.0552, acc=1.0000\n",
      "Epoch 18, batch 100, loss=0.1650, acc=0.9688\n",
      "Eval: loss=0.1074, acc=0.9723\n",
      "Epoch 19 -------------------------------\n",
      "Epoch 19, batch 0, loss=0.0850, acc=0.9375\n",
      "Epoch 19, batch 100, loss=0.0599, acc=1.0000\n",
      "Eval: loss=0.1033, acc=0.9723\n",
      "Epoch 20 -------------------------------\n",
      "Epoch 20, batch 0, loss=0.0264, acc=1.0000\n",
      "Epoch 20, batch 100, loss=0.0262, acc=1.0000\n",
      "Eval: loss=0.0996, acc=0.9733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/26 15:56:57 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu121) contains a local version label (+cu121). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/10/26 15:57:00 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu121) contains a local version label (+cu121). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/10/26 15:57:00 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run treasured-loon-39 at: https://lyx51-mlflow.hf.space/#/experiments/9/runs/601969b1f09541c69051039a56eb8ef2\n",
      "ðŸ§ª View experiment at: https://lyx51-mlflow.hf.space/#/experiments/9\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run() as run:\n",
    "  params = {\n",
    "      \"epochs\": epochs,\n",
    "      \"learning_rate\": 1e-3,\n",
    "      \"batch_size\": 32,\n",
    "      \"loss_function\": loss_fn.__class__.__name__,\n",
    "      \"metric_function\": metric_fn.__class__.__name__,\n",
    "      \"optimizer\": optimizer.__class__.__name__,\n",
    "  }\n",
    "  # Log training parameters.\n",
    "  mlflow.log_params(params)\n",
    "\n",
    "  # Log model summary.\n",
    "  with open(\"model_summary.txt\", \"w\") as f:\n",
    "      f.write(str(summary(model)))\n",
    "  mlflow.log_artifact(\"model_summary.txt\")\n",
    "\n",
    "  for t in range(epochs):\n",
    "      print(f\"Epoch {t + 1} \\\n",
    "-------------------------------\")\n",
    "      train(train_loader, model, loss_fn, metric_fn, optimizer, epoch=t)\n",
    "      evaluate(val_loader, model, loss_fn, metric_fn, epoch=0)\n",
    "\n",
    "  # Save the trained model to MLflow.\n",
    "  model_info = mlflow.pytorch.log_model(model, name=\"SMS_Spam_Detector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a965749b",
   "metadata": {},
   "source": [
    "# 5. Test model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f7a0811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's   \""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = data['content'][2]\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f032447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(input):\n",
    "    tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    token = tokenizer.encode(input)\n",
    "    seq = [token[:25] + [0] * (25 - len(token))]\n",
    "    return seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "13f9d2c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9696844]], dtype=float32)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after training\n",
    "import numpy\n",
    "loaded_model = mlflow.pyfunc.load_model(model_info.model_uri)\n",
    "outputs = loaded_model.predict(np.array(preprocess(input)))\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db322ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9696844]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with register model\n",
    "\n",
    "mlflow.set_tracking_uri(os.environ[\"MLFLOW_TRACKING_URI\"])\n",
    "model_name = \"SMS_Spam_Detector_NN\"\n",
    "model_version = \"latest\"\n",
    "\n",
    "model = mlflow.pyfunc.load_model(f\"models:/{model_name}/{model_version}\")\n",
    "\n",
    "predict = model.predict(np.array(preprocess(input)))\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd67cfde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "if predict[0][0] > 0.96:\n",
    "    print('Spam')\n",
    "else:\n",
    "    print(\"Not Spam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f20d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_prediction(model, input):\n",
    "    prediction = model.predict(np.array(preprocess(input)))\n",
    "    return 'Spam' if prediction[0][0] > 0.5 else 'Not Spam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a2a182e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spam'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request_prediction(model, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad1064b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def request_prediction(model, input):\n",
    "#    prediction = model.predict(np.array(preprocess(input)))\n",
    " #   return 'spam' if prediction[0][0] > 0.5 else 'ham'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
